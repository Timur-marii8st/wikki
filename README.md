<div align="center">

# üå∏ Wikki v2.0 - AI Desktop Companion

**[ üá∑üá∫ –†—É—Å—Å–∫–∏–π ](#-—Ä—É—Å—Å–∫–∏–π) | [ üá¨üáß English ](#-english)**

</div>

---

## üá¨üáß English

> A cute AI companion with a 3D avatar that lives on your desktop and can talk to you.

### ‚ú® Features

- üí¨ **Chat with AI** - Talk to Gemma 3 via llama.cpp.
- üé≠ **3D Avatar** - A living character with emotions and animations.
- üîä **Text-to-Speech** - Wikki voices her responses.
- üé§ **Voice Input (STT)** - Speak to Wikki (Ctrl+Shift+V).
- üì∏ **Auto-screenshots** - Wikki sees what you are doing and comments on it.
- ü™ü **Dual Windows** - Avatar is always on top; chat window appears on demand.
- ü¶ô **Llama.cpp** - Manage the server directly from the application.

### üöÄ Quick Start

#### Requirements
- [Rust](https://rustup.rs/)
- [llama.cpp](https://github.com/ggerganov/llama.cpp) with the Gemma 3 model
- Node.js + pnpm

#### Installation
```bash
# 1. Build llama.cpp and download the model
# See LLAMA_CPP_GUIDE.md

# 2. Install dependencies
pnpm install

# 3. Run development mode
pnpm tauri dev

# 4. Click on the status dot in the UI to start the llama-server
```

More details: [LLAMA_CPP_GUIDE.md](LLAMA_CPP_GUIDE.md)

### üìñ Documentation

- [LLAMA_CPP_GUIDE.md](LLAMA_CPP_GUIDE.md) - Working with llama.cpp
- [SILERO_TTS_GUIDE.md](SILERO_TTS_GUIDE.md) - Silero TTS Setup
- [QUICK_3D_SETUP.md](QUICK_3D_SETUP.md) - Quick 3D model setup
- [3D_MODEL_GUIDE.md](3D_MODEL_GUIDE.md) - Full guide on 3D models
- [QUICKSTART.md](QUICKSTART.md) - Quick Start
- [SETUP.md](SETUP.md) - Detailed Installation
- [ROADMAP.md](ROADMAP.md) - Development Plan
- [CHANGES.md](CHANGES.md) - Changelog

### üéØ Project Status

#### ‚úÖ Implemented
- Basic chat with llama.cpp
- 3D Avatar (simple geometry)
- TTS (System synthesizer)
- **STT (Transcription via Gemma 3)** üÜï
- Automatic screenshots
- Voice recording (15s limit)
- **Control llama-server from UI** üÜï
- **Multimodality (text + audio + images)** üÜï

#### üöß In Progress
- High-quality 3D model (GLB)
- Settings UI

#### üìã Planned
- System tray menu
- History export
- Multi-language support
- Plugins

### üèóÔ∏è Architecture

```
Wikki v2.0
‚îú‚îÄ‚îÄ Frontend (React + Three.js)
‚îÇ   ‚îú‚îÄ‚îÄ Chat UI
‚îÇ   ‚îî‚îÄ‚îÄ 3D Avatar
‚îî‚îÄ‚îÄ Backend (Rust + Tauri)
    ‚îú‚îÄ‚îÄ Ollama Client
    ‚îú‚îÄ‚îÄ TTS Engine
    ‚îú‚îÄ‚îÄ Screenshot Service
    ‚îî‚îÄ‚îÄ Window Management
```

**Technologies:**
- Tauri 2.0 - Desktop framework
- React 18 - UI
- Three.js - 3D graphics
- Zustand - State management
- Ollama - Local LLM
- Rust - Backend

### üí° Why Wikki?

- **Privacy** - Everything runs locally.
- **Free** - No API costs.
- **Lightweight** - ~4.5GB RAM at peak.
- **Customizable** - Open Source.

### üìù License

MIT

### üôè Acknowledgements

- [Ollama](https://ollama.ai/) - Local LLM runtime
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - Local LLM inference
- [Silero TTS](https://github.com/snakers4/silero-models) - Neural TTS
- [Gemma 3](https://ai.google.dev/) - The model that powers Wikki
- [Tauri](https://tauri.app/) - Desktop framework
- [Three.js](https://threejs.org/) - 3D library
- [React Three Fiber](https://docs.pmnd.rs/react-three-fiber) - React renderer for Three.js

---

## üá∑üá∫ –†—É—Å—Å–∫–∏–π

> –ú–∏–ª—ã–π AI –∫–æ–º–ø–∞–Ω—å–æ–Ω —Å 3D –∞–≤–∞—Ç–∞—Ä–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∂–∏–≤–µ—Ç –Ω–∞ –≤–∞—à–µ–º —Ä–∞–±–æ—á–µ–º —Å—Ç–æ–ª–µ –∏ —Å –∫–æ—Ç–æ—Ä—ã–º –º–æ–∂–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—å.

### ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üí¨ **–ß–∞—Ç —Å AI** - –æ–±—â–∞–π—Ç–µ—Å—å —Å Gemma 3 —á–µ—Ä–µ–∑ llama.cpp
- üé≠ **3D –ê–≤–∞—Ç–∞—Ä** - –∂–∏–≤–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂ —Å —ç–º–æ—Ü–∏—è–º–∏ –∏ –∞–Ω–∏–º–∞—Ü–∏—è–º–∏
- üîä **Text-to-Speech** - Wikki –æ–∑–≤—É—á–∏–≤–∞–µ—Ç —Å–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã
- üé§ **–ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ (STT)** - –≥–æ–≤–æ—Ä–∏—Ç–µ —Å Wikki (Ctrl+Shift+V)
- üì∏ **–ê–≤—Ç–æ—Å–∫—Ä–∏–Ω—à–æ—Ç—ã** - Wikki –≤–∏–¥–∏—Ç, —á—Ç–æ –≤—ã –¥–µ–ª–∞–µ—Ç–µ, –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–µ—Ç
- ü™ü **–î–≤–∞ –æ–∫–Ω–∞** - –∞–≤–∞—Ç–∞—Ä –≤—Å–µ–≥–¥–∞ –ø–æ–≤–µ—Ä—Ö, —á–∞—Ç –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
- ü¶ô **Llama.cpp** - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–æ–º –ø—Ä—è–º–æ –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

### üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

#### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- [Rust](https://rustup.rs/)
- [llama.cpp](https://github.com/ggerganov/llama.cpp) —Å –º–æ–¥–µ–ª—å—é Gemma 3
- Node.js + pnpm

#### –£—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
# 1. –°–æ–±–µ—Ä–∏—Ç–µ llama.cpp –∏ —Å–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å
# –°–º. LLAMA_CPP_GUIDE.md

# 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pnpm install

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ
pnpm tauri dev

# 4. –í UI –∫–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ status dot –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ llama-server
```

–ü–æ–¥—Ä–æ–±–Ω–µ–µ: [LLAMA_CPP_GUIDE.md](LLAMA_CPP_GUIDE.md)

### üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [LLAMA_CPP_GUIDE.md](LLAMA_CPP_GUIDE.md) - –†–∞–±–æ—Ç–∞ —Å llama.cpp
- [SILERO_TTS_GUIDE.md](SILERO_TTS_GUIDE.md) - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Silero TTS
- [QUICK_3D_SETUP.md](QUICK_3D_SETUP.md) - –ë—ã—Å—Ç—Ä–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ 3D –º–æ–¥–µ–ª–∏
- [3D_MODEL_GUIDE.md](3D_MODEL_GUIDE.md) - –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ 3D –º–æ–¥–µ–ª—è–º
- [QUICKSTART.md](QUICKSTART.md) - –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
- [SETUP.md](SETUP.md) - –î–µ—Ç–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
- [ROADMAP.md](ROADMAP.md) - –ü–ª–∞–Ω —Ä–∞–∑–≤–∏—Ç–∏—è
- [CHANGES.md](CHANGES.md) - –°–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π

### üéØ –°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞

#### ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ
- –ë–∞–∑–æ–≤—ã–π —á–∞—Ç —Å llama.cpp
- 3D –∞–≤–∞—Ç–∞—Ä (–ø—Ä–æ—Å—Ç–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—è)
- TTS (—Å–∏—Å—Ç–µ–º–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä)
- **STT (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —á–µ—Ä–µ–∑ Gemma 3)** üÜï
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã
- –ì–æ–ª–æ—Å–æ–≤–∞—è –∑–∞–ø–∏—Å—å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º 15 —Å–µ–∫
- **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ llama-server –∏–∑ UI** üÜï
- **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å (—Ç–µ–∫—Å—Ç + –∞—É–¥–∏–æ + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)** üÜï

#### üöß –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ
- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è 3D –º–æ–¥–µ–ª—å (GLB)
- UI –Ω–∞—Å—Ç—Ä–æ–µ–∫

#### üìã –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è
- System tray –º–µ–Ω—é
- –≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏
- –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å
- –ü–ª–∞–≥–∏–Ω—ã

### üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
Wikki v2.0
‚îú‚îÄ‚îÄ Frontend (React + Three.js)
‚îÇ   ‚îú‚îÄ‚îÄ Chat UI
‚îÇ   ‚îî‚îÄ‚îÄ 3D Avatar
‚îî‚îÄ‚îÄ Backend (Rust + Tauri)
    ‚îú‚îÄ‚îÄ Ollama Client
    ‚îú‚îÄ‚îÄ TTS Engine
    ‚îú‚îÄ‚îÄ Screenshot Service
    ‚îî‚îÄ‚îÄ Window Management
```

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
- Tauri 2.0 - Desktop framework
- React 18 - UI
- Three.js - 3D graphics
- Zustand - State management
- Ollama - Local LLM
- Rust - Backend

### üí° –ü–æ—á–µ–º—É Wikki?

- **–ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å** - –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ
- **–ë–µ—Å–ø–ª–∞—Ç–Ω–æ** - –Ω–µ—Ç API costs
- **–õ–µ–≥–∫–æ–≤–µ—Å–Ω–æ** - ~4.5GB RAM –≤ –ø–∏–∫–µ
- **–ö–∞—Å—Ç–æ–º–∏–∑–∏—Ä—É–µ–º–æ** - –æ—Ç–∫—Ä—ã—Ç—ã–π –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥

### üìù –õ–∏—Ü–µ–Ω–∑–∏—è

MIT

### üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- [Ollama](https://ollama.ai/) - Local LLM runtime
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - Local LLM inference
- [Silero TTS](https://github.com/snakers4/silero-models) - Neural TTS
- [Gemma 3](https://ai.google.dev/) - The model that powers Wikki
- [Tauri](https://tauri.app/) - Desktop framework
- [Three.js](https://threejs.org/) - 3D library
- [React Three Fiber](https://docs.pmnd.rs/react-three-fiber) - React renderer for Three.js

---

Made with ‚ù§Ô∏è