# ü¶ô Llama.cpp Integration Guide

## –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å

Wikki —Ç–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å llama.cpp server –≤–º–µ—Å—Ç–æ Ollama!

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ llama.cpp:
- ‚úÖ –ü—Ä—è–º–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –º–æ–¥–µ–ª—å—é
- ‚úÖ –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å (—Ç–µ–∫—Å—Ç + –∞—É–¥–∏–æ + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
- ‚úÖ –ú–µ–Ω—å—à–µ overhead
- ‚úÖ –ì–∏–±–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –°–∫–∞—á–∞–π—Ç–µ llama.cpp

```bash
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
```

### 2. –°–æ–±–µ—Ä–∏—Ç–µ llama-server

**Windows:**
```bash
mkdir build
cd build
cmake ..
cmake --build . --config Release
```

–ë–∏–Ω–∞—Ä–Ω–∏–∫ –±—É–¥–µ—Ç –≤ `build\bin\llama-server.exe`

### 3. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å Gemma 3

–ü–æ–º–µ—Å—Ç–∏—Ç–µ –≤–∞—à—É GGUF –º–æ–¥–µ–ª—å –≤ –ø–∞–ø–∫—É `models/`

–ù–∞–ø—Ä–∏–º–µ—Ä:
```
C:\Users\elkgo\llama.cpp\models\gemma-3n-E4B-it-absolute-heresy-MPOA-iQ4_NL.gguf
```

### 4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Wikki

```bash
pnpm tauri dev
```

### 5. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—É—Ç–∏ –≤ UI

1. –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ —Ü–≤–µ—Ç–Ω—É—é —Ç–æ—á–∫—É –≤ titlebar
2. –í–≤–µ–¥–∏—Ç–µ –ø—É—Ç–∏ –∫ executable –∏ –º–æ–¥–µ–ª–∏
3. –ù–∞–∂–º–∏—Ç–µ "Start Server"

## üéØ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞

**–í–∞—Ä–∏–∞–Ω—Ç A: –ß–µ—Ä–µ–∑ UI Wikki**
- –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ status dot
- –í–≤–µ–¥–∏—Ç–µ –ø—É—Ç–∏
- –ù–∞–∂–º–∏—Ç–µ "Start Server"

**–í–∞—Ä–∏–∞–Ω—Ç B: –í—Ä—É—á–Ω—É—é**
```bash
cd C:\Users\elkgo\llama.cpp
build\bin\llama-server.exe -m models\gemma-3n-E4B-it-absolute-heresy-MPOA-iQ4_NL.gguf -ngl 99 -sm none -mg 0 --mmap --host 127.0.0.1 --port 8080

build\bin\llama-server.exe -m models\gemma-3n-E4B-it-absolute-heresy-MPOA-iQ4_NL.gguf -ngl 99 -sm none -mg 0 --host 0.0.0.0 --port 8080
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞

–¶–≤–µ—Ç–Ω–∞—è —Ç–æ—á–∫–∞ –≤ titlebar –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å:
- üü¢ –ó–µ–ª–µ–Ω—ã–π - —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç
- üî¥ –ö—Ä–∞—Å–Ω—ã–π - —Å–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
- üü° –ñ–µ–ª—Ç—ã–π - –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è/–æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è
- ‚ö™ –°–µ—Ä—ã–π - —Å—Ç–∞—Ç—É—Å –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω

### –ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ (STT)

1. –ù–∞–∂–º–∏—Ç–µ –∏ –¥–µ—Ä–∂–∏—Ç–µ –∫–Ω–æ–ø–∫—É –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ (–∏–ª–∏ Ctrl+Shift+V)
2. –ì–æ–≤–æ—Ä–∏—Ç–µ (–º–∞–∫—Å 15 —Å–µ–∫—É–Ω–¥)
3. –û—Ç–ø—É—Å—Ç–∏—Ç–µ –∫–Ω–æ–ø–∫—É
4. –ï—Å–ª–∏ –∞—É–¥–∏–æ >15 —Å–µ–∫, –ø–æ—è–≤–∏—Ç—Å—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ:
   - "OK" - –æ–±—Ä–µ–∑–∞—Ç—å –¥–æ 15 —Å–µ–∫ –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å
   - "Cancel" - –æ—Ç–º–µ–Ω–∏—Ç—å

## üé§ –†–∞–±–æ—Ç–∞ —Å –∞—É–¥–∏–æ

### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** 15 —Å–µ–∫—É–Ω–¥
- **–§–æ—Ä–º–∞—Ç:** WAV/WebM
- **Sample rate:** 16kHz
- **Channels:** Mono

### –ü–æ—á–µ–º—É 15 —Å–µ–∫—É–Ω–¥?

Gemma 3 —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –º–∞–∫—Å–∏–º—É–º 15 —Å–µ–∫—É–Ω–¥ –∞—É–¥–∏–æ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã.

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏?

1. Wikki –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
2. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
3. –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –æ–±—Ä–µ–∑–∞—Ç—å –∏–ª–∏ –æ—Ç–º–µ–Ω–∏—Ç—å
4. –ï—Å–ª–∏ –æ–±—Ä–µ–∑–∞—Ç—å - –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–µ—Ä–≤—ã–µ 15 —Å–µ–∫—É–Ω–¥

## üì∏ –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å

### –¢–µ–∫—Å—Ç + –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã —É–∂–µ —Ä–∞–±–æ—Ç–∞—é—Ç!

### –¢–µ–∫—Å—Ç + –ê—É–¥–∏–æ

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ (Ctrl+Shift+V)

### –¢–µ–∫—Å—Ç + –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + –ê—É–¥–∏–æ

–ü–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ, –Ω–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≥–æ—Ç–æ–≤–∞.

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã llama-server

```bash
-m <path>      # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
-ngl 99        # Offload –≤—Å–µ—Ö —Å–ª–æ–µ–≤ –Ω–∞ GPU (–µ—Å–ª–∏ –µ—Å—Ç—å)
-sm none       # Disable split mode
-mg 0          # Main GPU
--mmap         # Use memory mapping
--host         # Bind address
--port         # Port number
```

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç–æ–≤

–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: `http://127.0.0.1:8080`

–ß—Ç–æ–±—ã –∏–∑–º–µ–Ω–∏—Ç—å, –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ:
- `src-tauri/src/services/ollama.rs` - `DEFAULT_LLAMA_CPP_URL`
- `src-tauri/src/commands/llama.rs` - health check URL

## üêõ Troubleshooting

### –°–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è

**–ü—Ä–æ–±–ª–µ–º–∞:** "Failed to start llama-server"

**–†–µ—à–µ–Ω–∏—è:**
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –∫ executable –∏ –º–æ–¥–µ–ª–∏
2. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –ø–æ—Ä—Ç 8080 —Å–≤–æ–±–æ–¥–µ–Ω
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø—É—Å–∫ executable
4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Ä—É—á–Ω—É—é –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ

### –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å—Ç–∏–ª—Å—è, –Ω–æ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç

**–ü—Ä–æ–±–ª–µ–º–∞:** Status –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç "stopped" —Ö–æ—Ç—è –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–ø—É—â–µ–Ω

**–†–µ—à–µ–Ω–∏—è:**
1. –ü–æ–¥–æ–∂–¥–∏—Ç–µ 2-3 —Å–µ–∫—É–Ω–¥—ã –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ `http://127.0.0.1:8080/health` –≤ –±—Ä–∞—É–∑–µ—Ä–µ
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ llama-server

### –ê—É–¥–∏–æ –Ω–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç—Å—è

**–ü—Ä–æ–±–ª–µ–º–∞:** "Transcription failed"

**–†–µ—à–µ–Ω–∏—è:**
1. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WAV/WebM)
4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ (5-10 —Å–µ–∫—É–Ω–¥)

### –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–Ω–æ–≥–æ RAM

**–†–µ—à–µ–Ω–∏—è:**
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ (Q4 –≤–º–µ—Å—Ç–æ Q8)
2. –£–º–µ–Ω—å—à–∏—Ç–µ context size –≤ llama-server
3. –ó–∞–∫—Ä–æ–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

## üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | RAM | CPU |
|-----------|-----|-----|
| Gemma 3 4B (Q4) | ~4GB | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–ø—Ä–æ—Å–∞ |
| llama-server | ~100MB | Idle: 0%, Active: 50-100% |
| Wikki app | ~200MB | Idle: 1%, Active: 5% |
| **–í—Å–µ–≥–æ** | **~4.5GB** | **–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –Ω–∞–≥—Ä—É–∑–∫–∏** |

### –°–∫–æ—Ä–æ—Å—Ç—å

- **–¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç:** 1-5 —Å–µ–∫—É–Ω–¥
- **–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ:** 2-10 —Å–µ–∫—É–Ω–¥
- **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** 3-8 —Å–µ–∫—É–Ω–¥

## üîÑ –ú–∏–≥—Ä–∞—Ü–∏—è —Å Ollama

### –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å

1. **URL:** `localhost:11434` ‚Üí `127.0.0.1:8080`
2. **API:** `/api/chat` ‚Üí `/v1/chat/completions`
3. **–ó–∞–ø—É—Å–∫:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π ‚Üí –†—É—á–Ω–æ–π/UI

### –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å

Wikki –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞:
- Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- llama.cpp (—á–µ—Ä–µ–∑ `.with_llama_cpp()`)

–¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: **llama.cpp**

–ß—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ Ollama:
```rust
// src-tauri/src/lib.rs
let ollama = services::ollama::OllamaClient::new(); // –ë–µ–∑ .with_llama_cpp()
```

## üìù API Reference

### Tauri Commands

#### `start_llama_server`
```typescript
await invoke('start_llama_server', {
  exePath: 'C:\\path\\to\\llama-server.exe',
  modelPath: 'C:\\path\\to\\model.gguf'
});
```

#### `stop_llama_server`
```typescript
await invoke('stop_llama_server');
```

#### `get_llama_server_status`
```typescript
const status = await invoke<string>('get_llama_server_status');
// Returns: "running" | "stopped"
```

#### `check_llama_server_health`
```typescript
const isHealthy = await invoke<boolean>('check_llama_server_health');
```

#### `get_audio_info`
```typescript
const info = await invoke<{
  duration_secs: number;
  size_kb: number;
  exceeds_limit: boolean;
  max_duration_secs: number;
}>('get_audio_info', { audioBase64: '...' });
```

#### `transcribe_audio`
```typescript
const result = await invoke<{
  text: string;
  audio_info: AudioInfo;
  was_trimmed: boolean;
}>('transcribe_audio', {
  input: {
    audio_base64: '...',
    format: 'wav'
  },
  trimIfNeeded: true
});
```

## üéì –ü—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ

```typescript
import { invoke } from '@tauri-apps/api/core';

async function startServer() {
  try {
    await invoke('start_llama_server', {
      exePath: 'C:\\llama.cpp\\build\\bin\\llama-server.exe',
      modelPath: 'C:\\llama.cpp\\models\\gemma-3n.gguf'
    });
    
    // Wait for server to start
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    // Check health
    const isHealthy = await invoke('check_llama_server_health');
    console.log('Server healthy:', isHealthy);
  } catch (error) {
    console.error('Failed to start server:', error);
  }
}
```

### –ü—Ä–∏–º–µ—Ä 2: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫

```typescript
async function transcribeAudio(audioBase64: string) {
  try {
    // Check audio info first
    const info = await invoke('get_audio_info', { audioBase64 });
    
    if (info.exceeds_limit) {
      const shouldTrim = confirm(
        `Audio is ${info.duration_secs}s (max ${info.max_duration_secs}s). Trim?`
      );
      
      if (!shouldTrim) return;
    }
    
    // Transcribe
    const result = await invoke('transcribe_audio', {
      input: { audio_base64: audioBase64, format: 'wav' },
      trimIfNeeded: true
    });
    
    console.log('Transcribed:', result.text);
    if (result.was_trimmed) {
      console.warn('Audio was trimmed');
    }
  } catch (error) {
    console.error('Transcription failed:', error);
  }
}
```

## üîÆ –ë—É–¥—É—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è

- [ ] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ Wikki
- [ ] –ù–∞—Å—Ç—Ä–æ–π–∫–∏ llama-server —á–µ—Ä–µ–∑ UI
- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
- [ ] Streaming responses
- [ ] Batch processing –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ
- [ ] –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–π

---

**–í–µ—Ä—Å–∏—è:** 0.2.0  
**–î–∞—Ç–∞:** 2026-02-01  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç
